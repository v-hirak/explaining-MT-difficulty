{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sacrebleu.metrics import BLEU, CHRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Translation Scores DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    columns=[\"lang\", \"BLEU_num_beams_1\", \"chrF++_num_beams_1\", \"COMET_num_beams_1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Quality Scores for Beam Size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_data = pd.read_csv(\"../lang_data/lang_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from language to language-specific BLEU tokenizers\n",
    "BLEU_LANG_MAP = {\n",
    "    \"cmn_Hans\": \"zh\",\n",
    "    \"cmn_Hant\": \"zh\",\n",
    "    \"jpn_Jpan\": \"ja\",\n",
    "    \"kor_Hang\": \"ko\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in lang_data[\"lang\"]:\n",
    "    if (\n",
    "        f\"hyp.{lang}_1\" not in os.listdir(\"translations/num_beams_1/\")\n",
    "        or lang in scores[\"lang\"]\n",
    "    ): continue\n",
    "    # Reference sentences\n",
    "    with open(f\"../floresp-v2.0-rc.2/dev/dev.{lang}\") as ref:\n",
    "        sents_ref = [line.strip() for line in ref.readlines()]\n",
    "    # Translated sentences\n",
    "    with open(f\"translations/num_beams_1/hyp.{lang}_1\") as hyp:\n",
    "        sents_hyp = [line.strip() for line in hyp.readlines()]\n",
    "    trg_lang = BLEU_LANG_MAP.get(lang, None)\n",
    "    bleu_score = BLEU(trg_lang=trg_lang).corpus_score(sents_hyp, [sents_ref]).score\n",
    "    chrf_score = CHRF(word_order=2).corpus_score(sents_hyp, [sents_ref]).score\n",
    "    lang_scores = {\n",
    "        \"lang\": lang,\n",
    "        \"BLEU_num_beams_1\": bleu_score,\n",
    "        \"chrF++_num_beams_1\": chrf_score\n",
    "    }\n",
    "    scores = scores.append(lang_scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lang': 'fra_Latn', 'BLEU_num_beams_1': 24.688650807328536, 'chrF++_num_beams_1': 48.61267581492919}\n"
     ]
    }
   ],
   "source": [
    "with open(f\"../floresp-v2.0-rc.2/dev/dev.fra_Latn\") as ref:\n",
    "    sents_ref = [line.strip() for line in ref.readlines()]\n",
    "# Translated sentences\n",
    "with open(f\"translations/num_beams_1/hyp.fra_Latn_1\") as hyp:\n",
    "    sents_hyp = [line.strip() for line in hyp.readlines()]\n",
    "bleu_score = BLEU().corpus_score(sents_hyp, [sents_ref]).score\n",
    "chrf_score = CHRF(word_order=2).corpus_score(sents_hyp, [sents_ref]).score\n",
    "lang_scores = {\n",
    "    \"lang\": \"fra_Latn\",\n",
    "    \"BLEU_num_beams_1\": bleu_score,\n",
    "    \"chrF++_num_beams_1\": chrf_score\n",
    "}\n",
    "print(lang_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sbatch comet.sh  # To be run on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = pd.read_csv(\"scores_2.csv\")\n",
    "scores_2.drop_duplicates(subset=\"lang\", inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>BLEU_num_beams_1</th>\n",
       "      <th>chrF++_num_beams_1</th>\n",
       "      <th>COMET_num_beams_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afr_Latn</td>\n",
       "      <td>37.496051</td>\n",
       "      <td>63.591824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arb_Arab</td>\n",
       "      <td>26.069451</td>\n",
       "      <td>53.587915</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bul_Cyrl</td>\n",
       "      <td>38.570824</td>\n",
       "      <td>62.250001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat_Latn</td>\n",
       "      <td>40.476136</td>\n",
       "      <td>62.695251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ces_Latn</td>\n",
       "      <td>29.600198</td>\n",
       "      <td>54.107049</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>wol_Latn</td>\n",
       "      <td>6.147244</td>\n",
       "      <td>28.263424</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>xho_Latn</td>\n",
       "      <td>13.017241</td>\n",
       "      <td>47.332211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>yor_Latn</td>\n",
       "      <td>5.639960</td>\n",
       "      <td>25.394067</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>yue_Hant</td>\n",
       "      <td>0.775981</td>\n",
       "      <td>17.332046</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>zul_Latn</td>\n",
       "      <td>17.813924</td>\n",
       "      <td>51.908824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang  BLEU_num_beams_1  chrF++_num_beams_1  COMET_num_beams_1\n",
       "0    afr_Latn         37.496051           63.591824                NaN\n",
       "1    arb_Arab         26.069451           53.587915                NaN\n",
       "2    bul_Cyrl         38.570824           62.250001                NaN\n",
       "3    cat_Latn         40.476136           62.695251                NaN\n",
       "4    ces_Latn         29.600198           54.107049                NaN\n",
       "..        ...               ...                 ...                ...\n",
       "119  wol_Latn          6.147244           28.263424                NaN\n",
       "120  xho_Latn         13.017241           47.332211                NaN\n",
       "121  yor_Latn          5.639960           25.394067                NaN\n",
       "122  yue_Hant          0.775981           17.332046                NaN\n",
       "123  zul_Latn         17.813924           51.908824                NaN\n",
       "\n",
       "[124 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2.to_csv(\"scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2_langs = scores_2[\"lang\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(translated_langs) - set(scores_2_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"scores.csv\")\n",
    "comet_scores = pd.read_csv(\"comet_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.merge(comet_scores, on=\"lang\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_recovered = pd.read_csv(\"../recovered/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.merge(scores_recovered, on=\"lang\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.drop(columns=[\"score\", \"BLEU_num_beams_1_y\", \"chrF++_num_beams_1_y\", \"COMET_num_beams_1_y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(\"scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = pd.read_csv(\"batch_1.csv\")\n",
    "batch_2 = pd.read_csv(\"batch_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_scores = pd.concat([batch_1, batch_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by lang\n",
    "comet_scores.sort_values(\"lang\", inplace=truncated_cube_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ace_Arab</td>\n",
       "      <td>0.6170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ace_Latn</td>\n",
       "      <td>0.5926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>acm_Arab</td>\n",
       "      <td>0.8089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afr_Latn</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>amh_Ethi</td>\n",
       "      <td>0.8743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>wol_Latn</td>\n",
       "      <td>0.6088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>xho_Latn</td>\n",
       "      <td>0.7618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>yor_Latn</td>\n",
       "      <td>0.6572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>yue_Hant</td>\n",
       "      <td>0.8311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>zul_Latn</td>\n",
       "      <td>0.7831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang   score\n",
       "33   ace_Arab  0.6170\n",
       "34   ace_Latn  0.5926\n",
       "35   acm_Arab  0.8089\n",
       "0    afr_Latn  0.8660\n",
       "36   amh_Ethi  0.8743\n",
       "..        ...     ...\n",
       "118  wol_Latn  0.6088\n",
       "119  xho_Latn  0.7618\n",
       "120  yor_Latn  0.6572\n",
       "121  yue_Hant  0.8311\n",
       "122  zul_Latn  0.7831\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comet_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_scores.to_csv(\"comet_scores_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_scores.rename(columns={\"score\": \"COMET_num_beams_1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.merge(comet_scores, on=\"lang\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(\"bullshit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 27776.85it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "! comet-score -s dev.eng_Latn -t translations/num_beams_1/hyp.fra_Latn_1 -r dev.fra_Latn --gpus 0 --quiet --only_system >> comet_fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by lang\n",
    "scores.sort_values(\"lang\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(\"scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Quality Gain per `num_beams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"scores/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain from num_beams=1 to num_beams=3\n",
    "scores[\"BLEU_num_beams_3_gain\"] = (scores[\"BLEU_num_beams_3\"] - scores[\"BLEU_num_beams_1\"])\n",
    "scores[\"chrF++_num_beams_3_gain\"] = scores[\"chrF++_num_beams_3\"] - scores[\"chrF++_num_beams_1\"]\n",
    "scores[\"COMET_num_beams_3_gain\"] = scores[\"COMET_num_beams_3\"] - scores[\"COMET_num_beams_1\"]\n",
    "\n",
    "# Gain from num_beams=3 to num_beams=5\n",
    "scores[\"BLEU_num_beams_5_gain\"] = scores[\"BLEU_num_beams_5\"] - scores[\"BLEU_num_beams_3\"]\n",
    "scores[\"chrF++_num_beams_5_gain\"] = scores[\"chrF++_num_beams_5\"] - scores[\"chrF++_num_beams_3\"]\n",
    "scores[\"COMET_num_beams_5_gain\"] = scores[\"COMET_num_beams_5\"] - scores[\"COMET_num_beams_3\"]\n",
    "\n",
    "# Gain from num_beams=5 to num_beams=7\n",
    "scores[\"BLEU_num_beams_7_gain\"] = scores[\"BLEU_num_beams_7\"] - scores[\"BLEU_num_beams_5\"]\n",
    "scores[\"chrF++_num_beams_7_gain\"] = scores[\"chrF++_num_beams_7\"] - scores[\"chrF++_num_beams_5\"]\n",
    "scores[\"COMET_num_beams_7_gain\"] = scores[\"COMET_num_beams_7\"] - scores[\"COMET_num_beams_5\"]\n",
    "\n",
    "# Total gain from num_beams=1 to num_beams=7\n",
    "scores[\"BLEU_gain_total\"] = scores[\"BLEU_num_beams_7\"] - scores[\"BLEU_num_beams_1\"]\n",
    "scores[\"chrF++_gain_total\"] = scores[\"chrF++_num_beams_7\"] - scores[\"chrF++_num_beams_1\"]\n",
    "scores[\"COMET_gain_total\"] = scores[\"COMET_num_beams_7\"] - scores[\"COMET_num_beams_1\"]\n",
    "\n",
    "# Total gain from num_beams=1 to num_beams=7 as a percentage of num_beams=1\n",
    "scores[\"BLEU_gain_total_pct\"] = (scores[\"BLEU_gain_total\"] / scores[\"BLEU_num_beams_1\"]) * 100\n",
    "scores[\"chrF++_gain_total_pct\"] = (scores[\"chrF++_gain_total\"] / scores[\"chrF++_num_beams_1\"]) * 100\n",
    "scores[\"COMET_gain_total_pct\"] = (scores[\"COMET_gain_total\"] / scores[\"COMET_num_beams_1\"]) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns and drop average gain columns\n",
    "scores = scores[[\n",
    "    \"lang\",\n",
    "\n",
    "    # num_beams=1\n",
    "    \"BLEU_num_beams_1\", \"chrF++_num_beams_1\", \"COMET_num_beams_1\",\n",
    "\n",
    "    # num_beams=3\n",
    "    \"BLEU_num_beams_3\", \"BLEU_num_beams_3_gain\",\n",
    "    \"chrF++_num_beams_3\", \"chrF++_num_beams_3_gain\",\n",
    "    \"COMET_num_beams_3\", \"COMET_num_beams_3_gain\",\n",
    "\n",
    "    # num_beams=5\n",
    "    \"BLEU_num_beams_5\", \"BLEU_num_beams_5_gain\",\n",
    "    \"chrF++_num_beams_5\", \"chrF++_num_beams_5_gain\",\n",
    "    \"COMET_num_beams_5\", \"COMET_num_beams_5_gain\",\n",
    "\n",
    "    # num_beams=7\n",
    "    \"BLEU_num_beams_7\", \"BLEU_num_beams_7_gain\",\n",
    "    \"chrF++_num_beams_7\", \"chrF++_num_beams_7_gain\",\n",
    "    \"COMET_num_beams_7\", \"COMET_num_beams_7_gain\",\n",
    "\n",
    "    # Total gain from num_beams=1 to num_beams=7\n",
    "    \"BLEU_gain_total\", \"chrF++_gain_total\", \"COMET_gain_total\",\n",
    "\n",
    "    # Total gain from num_beams=1 to num_beams=7 as a percentage of num_beams=1\n",
    "    \"BLEU_gain_total_pct\", \"chrF++_gain_total_pct\", \"COMET_gain_total_pct\",\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(\"scores/scores.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
