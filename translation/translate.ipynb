{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../floresp-v2.0-rc.2/dev/dev.eng_Latn\", encoding=\"UTF-8\") as f:\n",
    "    sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[256047,   2153, 126376, 248079, 234283,   5057,    349, 151618,  19879,\n",
       "          29470,    452, 122267, 200932,    349,   4701, 178399,    452,      9,\n",
       "          10413, 131647,  70441,   1482,   2125,  24942, 149257,    811,  27888,\n",
       "         248144,      9,  27594,    131,   3375,   2300,  22743,   1482,   2125,\n",
       "            280,  78537,  61627,  52365,  23106,   7691,   2919,   3995,  10771,\n",
       "            351,   9810,  31433,   6959,   4990,    261, 248075, 248137, 248075,\n",
       "           4868,  25026, 248075, 248059,      2]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sentences[0]\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "model.to(device); inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the `lang_code_to_id` attribute is deprecated. The logic is natively handled in the `tokenizer.adder_tokens_decoder` this attribute will be removed in `transformers` v4.38\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation/utils.py:2463: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    }
   ],
   "source": [
    "translated_tokens = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"fra_Latn\"],\n",
    "    num_beams=1,\n",
    "    num_return_sequences=1,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 92])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_tokens.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = tokenizer.batch_decode(translated_tokens.sequences, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_scores = model.compute_transition_scores(\n",
    "    translated_tokens.sequences,\n",
    "    translated_tokens.scores,\n",
    "    beam_indices=None,\n",
    "    normalize_logits=True\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 256057 | fra_Latn | 0.000 | 100.00%\n",
      "|   155 | L        | -0.798 | 45.04%\n",
      "|  7352 | undi     | -0.037 | 96.35%\n",
      "| 248079 | ,        | -0.241 | 78.55%\n",
      "|   702 | des      | -0.409 | 66.40%\n",
      "| 69805 | scienti  | -0.125 | 88.22%\n",
      "| 70342 | fiques   | -0.042 | 95.89%\n",
      "|    79 | de       | -0.096 | 90.86%\n",
      "|    55 | l        | -0.692 | 50.08%\n",
      "| 248116 | '        | -0.090 | 91.38%\n",
      "| 249117 | É        | -0.884 | 41.33%\n",
      "| 46696 | cole     | -0.043 | 95.79%\n",
      "|    79 | de       | -0.115 | 89.12%\n",
      "| 198450 | méde     | -0.115 | 89.14%\n",
      "| 39039 | cine     | -0.057 | 94.44%\n",
      "|    79 | de       | -0.104 | 90.14%\n",
      "|    55 | l        | -0.119 | 88.75%\n",
      "| 248116 | '        | -0.089 | 91.45%\n",
      "| 89559 | Univers  | -0.339 | 71.27%\n",
      "|  6610 | ité      | -0.061 | 94.08%\n",
      "|    79 | de       | -0.221 | 80.16%\n",
      "| 151618 | Stanford | -0.105 | 90.00%\n",
      "|  5303 | ont      | -0.141 | 86.87%\n",
      "| 98884 | annon    | -0.064 | 93.81%\n",
      "| 25535 | cé       | -0.059 | 94.24%\n",
      "|    55 | l        | -0.317 | 72.81%\n",
      "| 248116 | '        | -0.087 | 91.65%\n",
      "|    12 | in       | -0.245 | 78.29%\n",
      "| 36629 | vention  | -0.046 | 95.49%\n",
      "|    13 | d        | -0.121 | 88.61%\n",
      "| 248116 | '        | -0.082 | 92.17%\n",
      "|    24 | un       | -0.110 | 89.61%\n",
      "| 93370 | nouvel   | -0.310 | 73.36%\n",
      "|  1795 | ou       | -0.131 | 87.71%\n",
      "|  2982 | til      | -0.058 | 94.40%\n",
      "|    79 | de       | -0.469 | 62.55%\n",
      "| 131647 | diagnostic | -0.129 | 87.87%\n",
      "| 143147 | capable  | -1.235 | 29.08%\n",
      "|    79 | de       | -0.123 | 88.40%\n",
      "|  3690 | tri      | -0.117 | 88.96%\n",
      "|    14 | er       | -0.077 | 92.62%\n",
      "|   591 | les      | -0.185 | 83.12%\n",
      "|  6293 | cel      | -0.039 | 96.16%\n",
      "| 171388 | lules    | -0.031 | 96.90%\n",
      "|   413 | par      | -0.244 | 78.37%\n",
      "| 27888 | type     | -0.075 | 92.81%\n",
      "| 248144 | :        | -0.192 | 82.55%\n",
      "|  3335 | une      | -0.161 | 85.13%\n",
      "| 107806 | minus    | -0.708 | 49.26%\n",
      "| 77947 | cule     | -0.043 | 95.76%\n",
      "|  1350 | pu       | -0.010 | 99.05%\n",
      "|   271 | ce       | -0.062 | 94.01%\n",
      "| 29489 | impr     | -0.213 | 80.85%\n",
      "|    75 | im       | -0.143 | 86.66%\n",
      "| 20523 | able     | -0.193 | 82.48%\n",
      "|  2502 | qui      | -0.556 | 57.36%\n",
      "| 14120 | peut     | -0.145 | 86.50%\n",
      "| 14175 | être     | -0.093 | 91.13%\n",
      "| 159909 | fabri    | -0.216 | 80.56%\n",
      "| 178184 | quée     | -0.079 | 92.43%\n",
      "|   679 | à        | -0.402 | 66.89%\n",
      "|    55 | l        | -0.174 | 84.02%\n",
      "| 248116 | '        | -0.084 | 91.97%\n",
      "| 99554 | aide     | -0.044 | 95.68%\n",
      "|    13 | d        | -0.232 | 79.30%\n",
      "| 248116 | '        | -0.082 | 92.08%\n",
      "|    75 | im       | -0.318 | 72.79%\n",
      "| 42808 | prim     | -0.251 | 77.82%\n",
      "|  7272 | antes    | -0.076 | 92.68%\n",
      "|   679 | à        | -1.273 | 27.99%\n",
      "|  9399 | jet      | -0.314 | 73.02%\n",
      "|    13 | d        | -0.077 | 92.59%\n",
      "| 248116 | '        | -0.090 | 91.39%\n",
      "| 15992 | enc      | -0.005 | 99.47%\n",
      "|   119 | re       | -0.032 | 96.87%\n",
      "| 23106 | standard | -0.359 | 69.80%\n",
      "|  3340 | pour     | -1.329 | 26.48%\n",
      "| 150524 | environ  | -1.784 | 16.80%\n",
      "|   159 | un       | -0.303 | 73.86%\n",
      "| 86507 | centi    | -0.369 | 69.15%\n",
      "|   338 | me       | -0.073 | 92.94%\n",
      "|    79 | de       | -1.196 | 30.25%\n",
      "| 86507 | centi    | -1.597 | 20.25%\n",
      "|   338 | me       | -0.136 | 87.29%\n",
      "|    79 | de       | -1.595 | 20.30%\n",
      "|    55 | l        | -1.535 | 21.54%\n",
      "| 248116 | '        | -0.095 | 90.92%\n",
      "|    24 | un       | -1.195 | 30.28%\n",
      "| 248075 | .        | -0.849 | 42.78%\n",
      "| 248059 |          | -0.451 | 63.72%\n",
      "|     2 | </s>     | -0.113 | 89.34%\n"
     ]
    }
   ],
   "source": [
    "input_length = 1 if model.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
    "generated_tokens = translated_tokens.sequences[:, input_length:]\n",
    "\n",
    "probs, log_probs = [], []\n",
    "\n",
    "output_length = np.sum(transition_scores.numpy() < 0, axis=1)\n",
    "\n",
    "for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "    if not tok.item() == 1:\n",
    "        probs.append(np.exp(score.numpy()))\n",
    "        log_probs.append(score.numpy())\n",
    "        print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71085750150298"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.341283289092666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(output_length[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, -0.7976, -0.0372, -0.2414, -0.4094, -0.1253, -0.0419, -0.0959,\n",
       "        -0.6916, -0.0901, -0.8836, -0.0431, -0.1152, -0.1149, -0.0572, -0.1038,\n",
       "        -0.1194, -0.0894, -0.3387, -0.0610, -0.2212, -0.1054, -0.1408, -0.0639,\n",
       "        -0.0593, -0.3174, -0.0872, -0.2447, -0.0461, -0.1210, -0.0816, -0.1098,\n",
       "        -0.3098, -0.1312, -0.0577, -0.4692, -0.1293, -1.2351, -0.1233, -0.1170,\n",
       "        -0.0767, -0.1849, -0.0392, -0.0315, -0.2437, -0.0746, -0.1918, -0.1610,\n",
       "        -0.7081, -0.0433, -0.0096, -0.0618, -0.2125, -0.1432, -0.1926, -0.5559,\n",
       "        -0.1450, -0.0928, -0.2161, -0.0787, -0.4021, -0.1741, -0.0837, -0.0442,\n",
       "        -0.2319, -0.0825, -0.3176, -0.2507, -0.0760, -1.2732, -0.3144, -0.0770,\n",
       "        -0.0900, -0.0053, -0.0318, -0.3595, -1.3288, -1.7838, -0.3030, -0.3689,\n",
       "        -0.0732, -1.1956, -1.5971, -0.1359, -1.5946, -1.5355, -0.0952, -1.1948,\n",
       "        -0.8492, -0.4507, -0.1127])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_scores = transition_scores.sum(axis=1) / output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_scores[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_prob = np.prod(probs)\n",
    "sequence_log_prob = np.sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0970021e-13, -28.523352)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_prob, sequence_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 0,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 200,\n",
       "  \"pad_token_id\": 1\n",
       "}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(sequence_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([256057,    155,   7352, 248079,    702,  69805,  70342,     79,     55,\n",
       "        248116, 249117,  46696,     79, 198450,  39039,     79,     55, 248116,\n",
       "         89559,   6610,     79, 151618,   5303,  98884,  25535,     55, 248116,\n",
       "            12,  36629,     13, 248116,     24,  93370,   1795,   2982,     79,\n",
       "        131647, 143147,     79,   3690,     14,    591,   6293, 171388,    413,\n",
       "         27888, 248144,   3335, 107806,  77947,   1350,    271,  29489,     75,\n",
       "         20523,   2502,  14120,  14175, 159909, 178184,    679,     55, 248116,\n",
       "         99554,     13, 248116,     75,  42808,   7272,    679,   9399,     13,\n",
       "        248116,  15992,    119,  23106,   3340, 150524,    159,  86507,    338,\n",
       "            79,  86507,    338,     79,     55, 248116,     24, 248075, 248059,\n",
       "             2], device='mps:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lundi, des scientifiques de l'École de médecine de l'Université de Stanford ont annoncé l'invention d'un nouvel outil de diagnostic capable de trier les cellules par type: une minuscule puce imprimable qui peut être fabriquée à l'aide d'imprimantes à jet d'encre standard à environ un centime chacun. \""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3.11 chrF++.py -R floresp-v2.0-alpha.2/dev/dev.ita_Latn -H translations/1_beam/hyp.ita_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(58.8396, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sacrebleu ../floresp-v2.0-rc.2/dev/dev.ukr_Cyrl -i translations/num_beams_1/hyp.ukr_Cyrl_1 -m bleu chrf ter --chrf-word-order 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! comet-score -s floresp-v2.0-alpha.2/dev/dev.eng_Latn -t translations/1_beam/hyp.arb_Arab -r floresp-v2.0-alpha.2/dev/dev.arb_Arab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Translation Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jobs(num_beams: int, duration_mins: int) -> None:\n",
    "    \"\"\"Generate jobs for translation.\"\"\"\n",
    "\n",
    "    hours, minutes = duration_mins // 60, duration_mins % 60\n",
    "    time = f\"{hours}:{minutes}:00\"\n",
    "\n",
    "    selected_langs = (\n",
    "        pd.read_csv(\"../language_selection/selected_langs.csv\")\n",
    "        [\"lang\"].tolist()\n",
    "    )\n",
    "\n",
    "    for lang in selected_langs:\n",
    "        with open(f\"../jobs/translation/num_beams_{num_beams}/translate_{lang}_{num_beams}.sh\", \"w\") as f:\n",
    "            f.write(JOB_TEMPLATE.format(time=time, lang=lang, num_beams=num_beams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_TEMPLATE = \"\"\"#!/bin/bash\n",
    "\n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --job-name={lang}_1\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gpus-per-node=1\n",
    "\n",
    "source ~/thesis/venv/bin/activate\n",
    "python ~/thesis/translate.py -t {lang} -nb 1\n",
    "deactivate\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours, minutes = 30 // 60, 30 % 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{hours}:{minutes}:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_langs = (\n",
    "    pd.read_csv(\"../language_selection/selected_langs.csv\")\n",
    "    [\"lang\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_langs = (\n",
    "    pd.read_csv(\"../language_selection/union_langs.csv\")\n",
    "    [\"lang\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afr_Latn\n",
      "arb_Arab\n",
      "bel_Cyrl\n",
      "bul_Cyrl\n",
      "cat_Latn\n",
      "ces_Latn\n",
      "cmn_Hans\n",
      "cmn_Hant\n",
      "cym_Latn\n",
      "dan_Latn\n",
      "deu_Latn\n",
      "ekk_Latn\n",
      "ell_Grek\n",
      "eus_Latn\n",
      "fin_Latn\n",
      "fra_Latn\n",
      "gla_Latn\n",
      "gle_Latn\n",
      "glg_Latn\n",
      "heb_Hebr\n",
      "hin_Deva\n",
      "hrv_Latn\n",
      "hun_Latn\n",
      "hye_Armn\n",
      "ind_Latn\n",
      "isl_Latn\n",
      "ita_Latn\n",
      "jpn_Jpan\n",
      "kaz_Cyrl\n",
      "kor_Hang\n",
      "lit_Latn\n",
      "mar_Deva\n",
      "nld_Latn\n",
      "pes_Arab\n",
      "pol_Latn\n",
      "por_Latn\n",
      "ron_Latn\n",
      "rus_Cyrl\n",
      "san_Deva\n",
      "slk_Latn\n",
      "slv_Latn\n",
      "spa_Latn\n",
      "srp_Cyrl\n",
      "swe_Latn\n",
      "tam_Taml\n",
      "tel_Telu\n",
      "tur_Latn\n",
      "uig_Arab\n",
      "ukr_Cyrl\n",
      "urd_Arab\n",
      "vie_Latn\n",
      "wol_Latn\n"
     ]
    }
   ],
   "source": [
    "for lang in union_langs:\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in selected_langs:\n",
    "    with open(f\"../jobs/translation/num_beams_1/translate_{lang}_1.sh\", \"w\") as f:\n",
    "        f.write(JOB_TEMPLATE.format(lang=lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort langs_to_translate by \"lang\"\n",
    "langs_to_translate = langs_to_translate.sort_values(\"lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_to_translate.to_csv(\"langs_to_translate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_feat_langs = pd.read_csv(\"any_feat_langs.csv\")\n",
    "any_feat_langs = any_feat_langs[\"lang\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "translated_langs = [\n",
    "    filename[4:12]\n",
    "    for filename in os.listdir(\"../translation/translations/num_beams_1/\")\n",
    "    if filename != \".DS_Store\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"../translation/scores.csv\")\n",
    "scored_langs = scores[\"lang\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_to_score = set(translated_langs) - set(scored_langs)\n",
    "langs_to_score = sorted(list(langs_to_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs_to_score:\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = pd.read_csv(\"scores_2.csv\")\n",
    "scores_2.drop_duplicates(subset=\"lang\", inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2_langs = scores_2[\"lang\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(translated_langs) - set(scores_2_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"../translation/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_langs = lang_data[lang_data[\"lang\"].isin(scores[\"lang\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_langs.to_csv(\"selected_langs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fucking figuring out which other languages i need to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_langs = pd.read_csv(\"../language_selection/all_langs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
